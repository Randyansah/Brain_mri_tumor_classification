{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+6gIySOVz45ITYJ5P2PxS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Randyansah/Brain_mri_tumor_classification/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cny56IccU7z2",
        "outputId": "2415b154-8707-4be1-9ca0-139e14d4510c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Brain_mri_tumor_classification'...\n",
            "remote: Enumerating objects: 6847, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 6847 (delta 46), reused 102 (delta 43), pack-reused 6742\u001b[K\n",
            "Receiving objects: 100% (6847/6847), 140.82 MiB | 39.23 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Updating files: 100% (7044/7044), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Randyansah/Brain_mri_tumor_classification.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Brain_mri_tumor_classification/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2QGO3HhVASJ",
        "outputId": "05c7e9b3-8c0e-4652-a49b-f0646aa4432e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Brain_mri_tumor_classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W4IGlAHVHvK",
        "outputId": "3e732d8d-c704-44ff-c5d5-d6c8dc028708"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-18 15:25:06.592760: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-18 15:25:07.596513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-18 15:25:11.059624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:11.633643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:11.633948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:11.634977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:11.635229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:11.635435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:14.195457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:14.195835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:14.196076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-18 15:25:14.196215: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-10-18 15:25:14.196283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.225802: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.225837: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.225855: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.244328: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.247418: I tensorflow/core/common_runtime/placer.cc:114] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.247445: I tensorflow/core/common_runtime/placer.cc:114] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.248203: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.249193: I tensorflow/core/common_runtime/placer.cc:114] resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.249227: I tensorflow/core/common_runtime/placer.cc:114] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.249252: I tensorflow/core/common_runtime/placer.cc:114] AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.249806: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.251850: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.252045: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.253439: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2023-10-18 15:25:14.253645: I tensorflow/core/common_runtime/eager/execute.cc:1678] Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "100% 1321/1321 [00:06<00:00, 214.57it/s]\n",
            "100% 300/300 [00:02<00:00, 125.71it/s]\n",
            "100% 1339/1339 [00:06<00:00, 223.03it/s]\n",
            "100% 306/306 [00:01<00:00, 248.27it/s]\n",
            "100% 1595/1595 [00:05<00:00, 274.61it/s]\n",
            "100% 404/404 [00:00<00:00, 411.12it/s]\n",
            "100% 1457/1457 [00:06<00:00, 210.97it/s]\n",
            "100% 300/300 [00:01<00:00, 214.45it/s]\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}